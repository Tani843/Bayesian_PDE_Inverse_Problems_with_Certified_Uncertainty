# Cursor AI Instructions for Bayesian PDE Inverse Problems

## Project Overview
This is a research-grade implementation of Bayesian methods for solving inverse problems in partial differential equations with certified uncertainty quantification. The project combines rigorous mathematical theory with practical computational tools.

## Coding Standards

### Python Style Guidelines
- **PEP 8 Compliance**: Strict adherence to PEP 8 style guide
- **Type Hints**: All functions must include comprehensive type hints using `typing` module
- **Docstrings**: Use NumPy-style docstrings for all classes, functions, and modules
- **Line Length**: Maximum 88 characters (Black formatter standard)
- **Import Organization**: Imports organized as: stdlib, third-party, local modules

### Code Structure Requirements
```python
"""
Module docstring with detailed description.

This module implements [specific functionality] for the Bayesian PDE solver.
Key features include...

Examples:
    >>> from bayesian_pde_solver.module import Class
    >>> obj = Class(param1=value1)
    >>> result = obj.method()
"""

import os
from typing import Dict, List, Optional, Tuple, Union, Any
from abc import ABC, abstractmethod

import numpy as np
import scipy.sparse as sp
from scipy.optimize import minimize


class ExampleClass:
    """
    Brief class description.
    
    Longer description with mathematical background if relevant.
    
    Parameters
    ----------
    param1 : float
        Description of parameter
    param2 : Optional[str], default=None
        Description with default value
        
    Attributes
    ----------
    attribute1 : np.ndarray
        Description of attribute
        
    Examples
    --------
    >>> solver = ExampleClass(param1=1.0)
    >>> result = solver.compute()
    """
    
    def __init__(self, param1: float, param2: Optional[str] = None) -> None:
        self.param1 = param1
        self.param2 = param2
        self._validate_inputs()
    
    def _validate_inputs(self) -> None:
        """Validate constructor inputs."""
        if self.param1 <= 0:
            raise ValueError("param1 must be positive")
    
    def compute(self) -> np.ndarray:
        """
        Compute main operation.
        
        Returns
        -------
        result : np.ndarray
            Computed result array
            
        Raises
        ------
        RuntimeError
            If computation fails
        """
        try:
            # Implementation here
            pass
        except Exception as e:
            raise RuntimeError(f"Computation failed: {e}") from e
```

## Mathematical Notation Guidelines

### LaTeX in Docstrings
Use proper LaTeX notation in docstrings for mathematical expressions:

```python
def solve_pde(self, diffusion: float) -> np.ndarray:
    """
    Solve elliptic PDE: -∇·(D∇u) + ru = f in Ω.
    
    The weak formulation finds u ∈ H₀¹(Ω) such that:
    ∫_Ω D∇u·∇v dx + ∫_Ω ruv dx = ∫_Ω fv dx ∀v ∈ H₀¹(Ω)
    
    Parameters
    ----------
    diffusion : float
        Diffusion coefficient D > 0
        
    Returns
    -------
    solution : np.ndarray, shape (n_dof,)
        Finite element solution coefficients
    """
```

### Variable Naming Conventions
- `theta` or `params`: Parameter vectors
- `u`, `solution`: PDE solution fields
- `A`, `system_matrix`: System matrices
- `b`, `rhs`: Right-hand side vectors
- `sigma`, `noise_std`: Noise parameters
- `mu`, `mean`: Mean values
- `cov`, `covariance`: Covariance matrices

## Python Library Preferences

### Core Scientific Computing
```python
import numpy as np                    # Numerical arrays and operations
import scipy.sparse as sp            # Sparse matrices
from scipy.sparse.linalg import spsolve, cg, gmres
from scipy.optimize import minimize, minimize_scalar
from scipy.stats import multivariate_normal, invgamma
from scipy.interpolate import RegularGridInterpolator
```

### Statistical and Bayesian Libraries
```python
import emcee                         # MCMC sampling (preferred)
import arviz as az                   # Bayesian analysis
# Alternative: import pymc as pm     # For advanced Bayesian modeling
```

### Visualization Libraries
```python
import matplotlib.pyplot as plt      # Primary plotting
import matplotlib as mpl
import seaborn as sns               # Statistical plots
import plotly.express as px        # Interactive plots
import plotly.graph_objects as go   # Custom interactive plots
```

### Utility Libraries
```python
import pandas as pd                 # Data manipulation
from tqdm import tqdm              # Progress bars
import h5py                        # HDF5 file handling
import yaml                        # Configuration files
from pathlib import Path           # File path handling
```

## Visualization Requirements

### Matplotlib Configuration
```python
# Academic publication style
plt.style.use('seaborn-v0_8-whitegrid')
mpl.rcParams.update({
    'font.family': 'serif',
    'font.size': 12,
    'axes.labelsize': 14,
    'axes.titlesize': 16,
    'xtick.labelsize': 10,
    'ytick.labelsize': 10,
    'legend.fontsize': 10,
    'figure.titlesize': 18,
    'lines.linewidth': 2,
    'grid.alpha': 0.3,
    'savefig.dpi': 300,
    'savefig.bbox': 'tight'
})
```

### Color Schemes
```python
ACADEMIC_COLORS = {
    'primary': '#1f77b4',      # Blue
    'secondary': '#ff7f0e',    # Orange  
    'success': '#2ca02c',      # Green
    'danger': '#d62728',       # Red
    'warning': '#9467bd',      # Purple
    'info': '#8c564b'          # Brown
}

UNCERTAINTY_COLORS = {
    'mean': '#1f77b4',
    'confidence_band': '#1f77b4',
    'prediction_band': '#ff7f0e', 
    'observations': '#d62728',
    'true_values': '#2ca02c'
}
```

### Plot Standards
- **Figure sizes**: (10, 6) for single plots, (12, 8) for subplots
- **DPI**: 300 for publication quality
- **Fonts**: Serif for academic papers, sans-serif for presentations
- **Grid**: Subtle grid with alpha=0.3
- **Color blind friendly**: Use distinct patterns and shapes

## Performance Guidelines

### Numerical Optimization
```python
# Prefer vectorized operations
good_example = np.sum(array1 * array2)
bad_example = sum(a * b for a, b in zip(array1, array2))

# Use sparse matrices for PDEs
A = sp.csr_matrix((data, (row_indices, col_indices)), shape=(n, n))

# Efficient linear solvers
solution = spsolve(A, b)  # Direct solve for small systems
solution, info = cg(A, b, tol=1e-8)  # Iterative for large systems
```

### Memory Management
```python
# Pre-allocate arrays when possible
samples = np.zeros((n_samples, n_params))
for i in range(n_samples):
    samples[i] = sample_function()

# Use appropriate data types
indices = np.array(data, dtype=np.int32)  # Don't use int64 unnecessarily
values = np.array(data, dtype=np.float64)  # Use float64 for precision
```

## Error Handling Patterns

### Input Validation
```python
def validate_pde_parameters(params: Dict[str, Any]) -> None:
    """Validate PDE parameter dictionary."""
    required_keys = ['diffusion', 'source']
    for key in required_keys:
        if key not in params:
            raise KeyError(f"Missing required parameter: {key}")
    
    if params['diffusion'] <= 0:
        raise ValueError("Diffusion coefficient must be positive")
```

### Numerical Stability
```python
def safe_log_sum_exp(log_values: np.ndarray) -> float:
    """Numerically stable log-sum-exp computation."""
    max_val = np.max(log_values)
    if not np.isfinite(max_val):
        return -np.inf
    return max_val + np.log(np.sum(np.exp(log_values - max_val)))
```

## Testing Requirements

### Unit Test Structure
```python
import pytest
import numpy as np
from numpy.testing import assert_allclose

class TestPDESolver:
    """Test suite for PDE solver functionality."""
    
    def setup_method(self):
        """Set up test fixtures."""
        self.solver = PDESolver(domain=(0, 1), mesh_size=50)
    
    def test_manufactured_solution(self):
        """Test against manufactured solution."""
        # Define manufactured solution and source
        def u_exact(x):
            return np.sin(np.pi * x)
        
        def source(x):
            return np.pi**2 * np.sin(np.pi * x)
        
        # Solve and compare
        solution = self.solver.solve({'source': source})
        expected = u_exact(self.solver.mesh)
        
        assert_allclose(solution, expected, rtol=1e-3)
    
    @pytest.mark.parametrize("mesh_size", [10, 20, 50])
    def test_convergence_rate(self, mesh_size):
        """Test mesh convergence."""
        # Implementation here
        pass
```

## Documentation Standards

### API Documentation
- All public methods must have comprehensive docstrings
- Include mathematical background where relevant
- Provide working examples in docstrings
- Document all parameters, returns, and raised exceptions

### Jupyter Notebook Style
```python
# Cell 1: Setup and imports
import numpy as np
import matplotlib.pyplot as plt
from bayesian_pde_solver import FiniteDifferenceSolver

# Set up plotting
plt.style.use('seaborn-v0_8')
%matplotlib inline

# Cell 2: Problem setup with markdown explanation
# ## Problem Formulation
# We consider the elliptic PDE: -∇²u + u = f in Ω = [0,1]²
```

## Git Workflow

### Commit Message Format
```
type(scope): brief description

Detailed explanation of changes if needed.

- Bullet points for multiple changes
- Reference issues with #123
```

Types: `feat`, `fix`, `docs`, `test`, `refactor`, `perf`

### Branch Naming
- `feature/description-of-feature`
- `bugfix/issue-description`
- `docs/documentation-updates`

## File Organization Principles

### Module Structure
```
module_name/
├── __init__.py          # Package initialization and exports
├── base.py              # Abstract base classes
├── core.py              # Main implementation
├── utils.py             # Helper functions
├── exceptions.py        # Custom exceptions
└── tests/
    ├── __init__.py
    ├── test_core.py
    └── test_utils.py
```

### Import Conventions
```python
# In __init__.py
from .core import MainClass, main_function
from .utils import helper_function

__all__ = ['MainClass', 'main_function', 'helper_function']

# In other modules
from .base import BaseClass
from ..utils.math_utils import special_function
```

## Configuration Management

### YAML Configuration Files
```yaml
# config/default.yaml
pde_solver:
  type: "finite_difference"
  mesh_size: [50, 50]
  boundary_conditions:
    type: "dirichlet"
    value: 0.0

mcmc:
  n_samples: 10000
  n_burn: 2000
  sampler_type: "metropolis_hastings"
  
uncertainty:
  confidence_level: 0.95
  certification_method: "pac_bayes"
```

## Performance Profiling

### Memory and Time Profiling
```python
import cProfile
from memory_profiler import profile

@profile
def expensive_function():
    # Implementation
    pass

# Run with: python -m cProfile -o profile.stats script.py
```

These guidelines ensure consistent, high-quality, and maintainable code throughout the project while maintaining academic rigor and computational efficiency.