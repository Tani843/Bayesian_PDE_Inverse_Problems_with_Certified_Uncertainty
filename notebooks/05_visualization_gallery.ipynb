{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization Gallery\n",
    "\n",
    "Comprehensive showcase of visualization capabilities for Bayesian PDE inverse problems:\n",
    "\n",
    "- **PDE Solution Plots**: 1D, 2D, 3D solution fields\n",
    "- **Bayesian Diagnostics**: MCMC traces, convergence, autocorrelation\n",
    "- **Uncertainty Visualization**: Confidence bands, prediction intervals\n",
    "- **Parameter Analysis**: Joint distributions, correlations, marginals\n",
    "- **Publication Quality**: Professional academic styling\n",
    "- **Interactive Elements**: Dynamic plots for exploration\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup and imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.patches import Ellipse\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import matplotlib.patches as patches\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "from scipy.interpolate import griddata\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from typing import Tuple, Dict, Any, Optional\n",
    "\n",
    "# Add project to path\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "# Enhanced plotting setup\n",
    "plt.style.use('seaborn-v0_8')\n",
    "plt.rcParams.update({\n",
    "    'figure.figsize': (12, 8),\n",
    "    'font.size': 12,\n",
    "    'axes.labelsize': 14,\n",
    "    'axes.titlesize': 16,\n",
    "    'xtick.labelsize': 12,\n",
    "    'ytick.labelsize': 12,\n",
    "    'legend.fontsize': 12,\n",
    "    'figure.titlesize': 18,\n",
    "    'lines.linewidth': 2,\n",
    "    'lines.markersize': 8,\n",
    "    'axes.grid': True,\n",
    "    'grid.alpha': 0.3,\n",
    "    'figure.dpi': 100,\n",
    "    'savefig.dpi': 300,\n",
    "    'savefig.bbox': 'tight'\n",
    "})\n",
    "\n",
    "# Custom color schemes\n",
    "academic_colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', \n",
    "                  '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf']\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"ðŸŽ¨ Visualization Gallery - Setup Complete!\")\n",
    "print(f\"ðŸ“Š Academic color palette loaded: {len(academic_colors)} colors\")\n",
    "print(f\"ðŸ“ Figure DPI: {plt.rcParams['figure.dpi']}, Save DPI: {plt.rcParams['savefig.dpi']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: PDE Solution Visualizations\n",
    "\n",
    "Professional visualization of PDE solutions in 1D, 2D, and 3D."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import or create visualization framework\n",
    "try:\n",
    "    from bayesian_pde_solver.visualization import (\n",
    "        PDEPlotter, BayesianPlotter, UncertaintyPlotter\n",
    "    )\n",
    "    print(\"âœ… Using framework visualization classes\")\n",
    "    viz_framework_available = True\n",
    "except ImportError:\n",
    "    print(\"ðŸ“ Creating custom visualization classes\")\n",
    "    viz_framework_available = False\n",
    "    \n",
    "    class PDEPlotter:\n",
    "        \"\"\"Professional PDE solution plotting.\"\"\"\n",
    "        \n",
    "        def __init__(self, style='academic'):\n",
    "            self.style = style\n",
    "            self.colors = academic_colors\n",
    "            \n",
    "        def plot_1d_solution(self, x, u, title=\"PDE Solution\", \n",
    "                            xlabel=\"x\", ylabel=\"u(x)\", \n",
    "                            analytical=None, observations=None):\n",
    "            \"\"\"Plot 1D PDE solution with optional analytical comparison.\"\"\"\n",
    "            fig, ax = plt.subplots(figsize=(10, 6))\n",
    "            \n",
    "            # Main solution\n",
    "            ax.plot(x, u, color=self.colors[0], linewidth=3, label='Numerical Solution')\n",
    "            \n",
    "            # Analytical solution if provided\n",
    "            if analytical is not None:\n",
    "                ax.plot(x, analytical, color=self.colors[1], linewidth=2, \n",
    "                       linestyle='--', label='Analytical Solution')\n",
    "            \n",
    "            # Observations if provided\n",
    "            if observations is not None:\n",
    "                obs_x, obs_u = observations\n",
    "                ax.scatter(obs_x, obs_u, color=self.colors[3], s=100, \n",
    "                          zorder=5, label='Observations', marker='o')\n",
    "            \n",
    "            ax.set_xlabel(xlabel)\n",
    "            ax.set_ylabel(ylabel)\n",
    "            ax.set_title(title)\n",
    "            ax.legend()\n",
    "            ax.grid(True, alpha=0.3)\n",
    "            \n",
    "            return fig, ax\n",
    "        \n",
    "        def plot_2d_solution(self, X, Y, U, title=\"2D PDE Solution\",\n",
    "                            colormap='viridis', levels=20, \n",
    "                            contour_lines=True, colorbar=True):\n",
    "            \"\"\"Plot 2D PDE solution as contour plot.\"\"\"\n",
    "            fig, ax = plt.subplots(figsize=(10, 8))\n",
    "            \n",
    "            # Filled contours\n",
    "            if isinstance(levels, int):\n",
    "                levels = np.linspace(np.min(U), np.max(U), levels)\n",
    "            \n",
    "            contourf = ax.contourf(X, Y, U, levels=levels, cmap=colormap, alpha=0.8)\n",
    "            \n",
    "            # Contour lines\n",
    "            if contour_lines:\n",
    "                contour = ax.contour(X, Y, U, levels=levels[::2], colors='black', \n",
    "                                   alpha=0.4, linewidths=0.8)\n",
    "                ax.clabel(contour, inline=True, fontsize=9, fmt='%.3f')\n",
    "            \n",
    "            # Colorbar\n",
    "            if colorbar:\n",
    "                cbar = plt.colorbar(contourf, ax=ax)\n",
    "                cbar.set_label('Solution Value')\n",
    "            \n",
    "            ax.set_xlabel('x')\n",
    "            ax.set_ylabel('y')\n",
    "            ax.set_title(title)\n",
    "            ax.set_aspect('equal')\n",
    "            \n",
    "            return fig, ax\n",
    "        \n",
    "        def plot_3d_surface(self, X, Y, U, title=\"3D PDE Solution\",\n",
    "                           colormap='viridis', alpha=0.8, wireframe=False):\n",
    "            \"\"\"Plot 3D surface of PDE solution.\"\"\"\n",
    "            fig = plt.figure(figsize=(12, 9))\n",
    "            ax = fig.add_subplot(111, projection='3d')\n",
    "            \n",
    "            if wireframe:\n",
    "                surf = ax.plot_wireframe(X, Y, U, alpha=alpha, linewidth=0.8)\n",
    "            else:\n",
    "                surf = ax.plot_surface(X, Y, U, cmap=colormap, alpha=alpha,\n",
    "                                     linewidth=0, antialiased=True)\n",
    "                \n",
    "                # Colorbar\n",
    "                cbar = plt.colorbar(surf, ax=ax, shrink=0.6)\n",
    "                cbar.set_label('Solution Value')\n",
    "            \n",
    "            ax.set_xlabel('x')\n",
    "            ax.set_ylabel('y')\n",
    "            ax.set_zlabel('u(x,y)')\n",
    "            ax.set_title(title)\n",
    "            \n",
    "            return fig, ax\n",
    "\n",
    "# Initialize plotter\n",
    "plotter = PDEPlotter(style='academic')\n",
    "print(\"âœ… PDE plotter initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate sample PDE solutions for demonstration\n",
    "def generate_demo_solutions():\n",
    "    \"\"\"Generate sample PDE solutions for visualization.\"\"\"\n",
    "    \n",
    "    # 1D solution: Heat equation with source\n",
    "    x_1d = np.linspace(0, 1, 101)\n",
    "    u_1d = np.sin(np.pi * x_1d) * np.exp(-0.1 * x_1d) + 0.1 * x_1d * (1 - x_1d)\n",
    "    u_analytical_1d = np.sin(np.pi * x_1d) / (np.pi**2 + 0.1)\n",
    "    \n",
    "    # 1D observations\n",
    "    obs_x_1d = np.array([0.2, 0.4, 0.6, 0.8])\n",
    "    obs_u_1d = np.interp(obs_x_1d, x_1d, u_1d) + np.random.normal(0, 0.01, len(obs_x_1d))\n",
    "    \n",
    "    # 2D solution: Poisson equation with complex source\n",
    "    x_2d = np.linspace(0, 1, 51)\n",
    "    y_2d = np.linspace(0, 1, 51)\n",
    "    X_2d, Y_2d = np.meshgrid(x_2d, y_2d)\n",
    "    \n",
    "    # Multi-scale solution with boundary layer\n",
    "    u_2d = (np.sin(2*np.pi*X_2d) * np.sin(2*np.pi*Y_2d) * \n",
    "            np.exp(-((X_2d-0.7)**2 + (Y_2d-0.3)**2)/0.05) +\n",
    "            0.1 * np.exp(-10*((X_2d-0.2)**2 + (Y_2d-0.8)**2)) +\n",
    "            0.05 * (X_2d * Y_2d * (1-X_2d) * (1-Y_2d)))\n",
    "    \n",
    "    return {\n",
    "        '1d': {'x': x_1d, 'u': u_1d, 'analytical': u_analytical_1d, \n",
    "               'observations': (obs_x_1d, obs_u_1d)},\n",
    "        '2d': {'X': X_2d, 'Y': Y_2d, 'U': u_2d}\n",
    "    }\n",
    "\n",
    "# Generate demo solutions\n",
    "np.random.seed(42)\n",
    "demo_solutions = generate_demo_solutions()\n",
    "\n",
    "print(\"ðŸ“Š Demo Solutions Generated:\")\n",
    "print(f\"   1D solution: {len(demo_solutions['1d']['x'])} points\")\n",
    "print(f\"   2D solution: {demo_solutions['2d']['X'].shape} grid\")\n",
    "print(f\"   Observations: {len(demo_solutions['1d']['observations'][0])} points\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Showcase 1D PDE solution visualization\n",
    "print(\"ðŸŽ¨ 1D PDE Solution Visualization Showcase\")\n",
    "\n",
    "# Extract 1D data\n",
    "sol_1d = demo_solutions['1d']\n",
    "\n",
    "# Create comprehensive 1D plot\n",
    "fig, ax = plotter.plot_1d_solution(\n",
    "    sol_1d['x'], sol_1d['u'], \n",
    "    title=\"1D Heat Equation with Source Term\",\n",
    "    xlabel=\"Position x\", ylabel=\"Temperature u(x)\",\n",
    "    analytical=sol_1d['analytical'],\n",
    "    observations=sol_1d['observations']\n",
    ")\n",
    "\n",
    "# Add error analysis\n",
    "error = np.abs(sol_1d['u'] - sol_1d['analytical'])\n",
    "ax2 = ax.twinx()\n",
    "ax2.plot(sol_1d['x'], error * 1000, color=academic_colors[4], \n",
    "         linestyle=':', alpha=0.7, label='Error Ã— 1000')\n",
    "ax2.set_ylabel('Error (Ã— 1000)', color=academic_colors[4])\n",
    "ax2.tick_params(axis='y', labelcolor=academic_colors[4])\n",
    "\n",
    "# Add text annotations\n",
    "ax.annotate('Maximum error region', \n",
    "           xy=(0.5, np.max(sol_1d['u'])), xytext=(0.7, np.max(sol_1d['u']) * 0.8),\n",
    "           arrowprops=dict(arrowstyle='->', color='black', alpha=0.7),\n",
    "           bbox=dict(boxstyle=\"round,pad=0.3\", facecolor='yellow', alpha=0.3))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Statistics\n",
    "max_error = np.max(error)\n",
    "l2_error = np.sqrt(np.trapz(error**2, sol_1d['x']))\n",
    "print(f\"ðŸ“ˆ Solution Quality:\")\n",
    "print(f\"   Maximum error: {max_error:.2e}\")\n",
    "print(f\"   LÂ² error: {l2_error:.2e}\")\n",
    "print(f\"   Solution range: [{np.min(sol_1d['u']):.3f}, {np.max(sol_1d['u']):.3f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Showcase 2D PDE solution visualizations\n",
    "print(\"ðŸŽ¨ 2D PDE Solution Visualization Showcase\")\n",
    "\n",
    "# Extract 2D data\n",
    "sol_2d = demo_solutions['2d']\n",
    "X, Y, U = sol_2d['X'], sol_2d['Y'], sol_2d['U']\n",
    "\n",
    "# Create multiple visualization styles\n",
    "fig = plt.figure(figsize=(18, 12))\n",
    "\n",
    "# 1. Filled contour plot\n",
    "ax1 = plt.subplot(2, 3, 1)\n",
    "contourf = ax1.contourf(X, Y, U, levels=20, cmap='viridis')\n",
    "ax1.set_title('Filled Contours (viridis)')\n",
    "ax1.set_xlabel('x')\n",
    "ax1.set_ylabel('y')\n",
    "plt.colorbar(contourf, ax=ax1)\n",
    "\n",
    "# 2. Line contours with labels\n",
    "ax2 = plt.subplot(2, 3, 2)\n",
    "levels = np.linspace(np.min(U), np.max(U), 15)\n",
    "contour = ax2.contour(X, Y, U, levels=levels, colors='black', linewidths=1.2)\n",
    "ax2.clabel(contour, inline=True, fontsize=9, fmt='%.3f')\n",
    "ax2.set_title('Contour Lines')\n",
    "ax2.set_xlabel('x')\n",
    "ax2.set_ylabel('y')\n",
    "ax2.set_aspect('equal')\n",
    "\n",
    "# 3. Combined contours and fills\n",
    "ax3 = plt.subplot(2, 3, 3)\n",
    "contourf = ax3.contourf(X, Y, U, levels=20, cmap='plasma', alpha=0.8)\n",
    "contour = ax3.contour(X, Y, U, levels=levels[::2], colors='white', \n",
    "                     linewidths=1.0, alpha=0.8)\n",
    "ax3.set_title('Combined (plasma colormap)')\n",
    "ax3.set_xlabel('x')\n",
    "ax3.set_ylabel('y')\n",
    "plt.colorbar(contourf, ax=ax3)\n",
    "\n",
    "# 4. 3D surface plot\n",
    "ax4 = plt.subplot(2, 3, 4, projection='3d')\n",
    "surf = ax4.plot_surface(X, Y, U, cmap='coolwarm', alpha=0.9,\n",
    "                       linewidth=0, antialiased=True)\n",
    "ax4.set_title('3D Surface')\n",
    "ax4.set_xlabel('x')\n",
    "ax4.set_ylabel('y')\n",
    "ax4.set_zlabel('u(x,y)')\n",
    "\n",
    "# 5. Wireframe plot\n",
    "ax5 = plt.subplot(2, 3, 5, projection='3d')\n",
    "wire = ax5.plot_wireframe(X, Y, U, alpha=0.7, linewidth=0.8, color='blue')\n",
    "ax5.set_title('3D Wireframe')\n",
    "ax5.set_xlabel('x')\n",
    "ax5.set_ylabel('y')\n",
    "ax5.set_zlabel('u(x,y)')\n",
    "\n",
    "# 6. Gradient magnitude\n",
    "ax6 = plt.subplot(2, 3, 6)\n",
    "# Compute gradient\n",
    "grad_x, grad_y = np.gradient(U)\n",
    "grad_mag = np.sqrt(grad_x**2 + grad_y**2)\n",
    "contourf = ax6.contourf(X, Y, grad_mag, levels=20, cmap='hot')\n",
    "ax6.set_title('Gradient Magnitude')\n",
    "ax6.set_xlabel('x')\n",
    "ax6.set_ylabel('y')\n",
    "plt.colorbar(contourf, ax=ax6)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Solution statistics\n",
    "print(f\"ðŸ“ˆ 2D Solution Statistics:\")\n",
    "print(f\"   Solution range: [{np.min(U):.4f}, {np.max(U):.4f}]\")\n",
    "print(f\"   Mean value: {np.mean(U):.4f}\")\n",
    "print(f\"   Standard deviation: {np.std(U):.4f}\")\n",
    "print(f\"   Gradient magnitude range: [{np.min(grad_mag):.4f}, {np.max(grad_mag):.4f}]\")\n",
    "print(f\"   Total variation: {np.sum(grad_mag) * (X[0,1] - X[0,0]) * (Y[1,0] - Y[0,0]):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: Bayesian Inference Diagnostics\n",
    "\n",
    "Comprehensive visualization of MCMC diagnostics and posterior analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Bayesian visualization class\n",
    "class BayesianPlotter:\n",
    "    \"\"\"Professional Bayesian inference visualization.\"\"\"\n",
    "    \n",
    "    def __init__(self, style='academic'):\n",
    "        self.style = style\n",
    "        self.colors = academic_colors\n",
    "        \n",
    "    def plot_trace_diagnostics(self, samples, parameter_names, \n",
    "                             true_values=None, burnin=None,\n",
    "                             include_autocorr=True):\n",
    "        \"\"\"Comprehensive MCMC trace diagnostics.\"\"\"\n",
    "        n_params = samples.shape[1]\n",
    "        n_samples = samples.shape[0]\n",
    "        \n",
    "        # Determine layout\n",
    "        if include_autocorr:\n",
    "            fig, axes = plt.subplots(n_params, 3, figsize=(18, 4*n_params))\n",
    "        else:\n",
    "            fig, axes = plt.subplots(n_params, 2, figsize=(15, 4*n_params))\n",
    "        \n",
    "        if n_params == 1:\n",
    "            axes = axes.reshape(1, -1)\n",
    "        \n",
    "        for i, param_name in enumerate(parameter_names):\n",
    "            param_samples = samples[:, i]\n",
    "            color = self.colors[i % len(self.colors)]\n",
    "            \n",
    "            # 1. Trace plot\n",
    "            axes[i, 0].plot(param_samples, color=color, alpha=0.8, linewidth=1)\n",
    "            if burnin is not None:\n",
    "                axes[i, 0].axvline(burnin, color='red', linestyle='--', \n",
    "                                  alpha=0.7, label='Burn-in')\n",
    "            if true_values is not None:\n",
    "                axes[i, 0].axhline(true_values[i], color='green', \n",
    "                                  linestyle='-', linewidth=2, label='True value')\n",
    "            axes[i, 0].set_title(f'Trace: {param_name}')\n",
    "            axes[i, 0].set_xlabel('Iteration')\n",
    "            axes[i, 0].set_ylabel(param_name)\n",
    "            axes[i, 0].legend()\n",
    "            axes[i, 0].grid(True, alpha=0.3)\n",
    "            \n",
    "            # 2. Marginal distribution\n",
    "            post_burnin = param_samples[burnin:] if burnin else param_samples\n",
    "            axes[i, 1].hist(post_burnin, bins=50, density=True, alpha=0.7, \n",
    "                           color=color, label='Posterior')\n",
    "            \n",
    "            # Add statistics\n",
    "            mean_val = np.mean(post_burnin)\n",
    "            std_val = np.std(post_burnin)\n",
    "            axes[i, 1].axvline(mean_val, color='black', linestyle='-', \n",
    "                              linewidth=2, label=f'Mean: {mean_val:.3f}')\n",
    "            axes[i, 1].axvline(mean_val - std_val, color='black', \n",
    "                              linestyle='--', alpha=0.7)\n",
    "            axes[i, 1].axvline(mean_val + std_val, color='black', \n",
    "                              linestyle='--', alpha=0.7, label=f'Â±1Ïƒ: {std_val:.3f}')\n",
    "            \n",
    "            if true_values is not None:\n",
    "                axes[i, 1].axvline(true_values[i], color='green', \n",
    "                                  linestyle='-', linewidth=2, label='True value')\n",
    "            \n",
    "            axes[i, 1].set_title(f'Marginal: {param_name}')\n",
    "            axes[i, 1].set_xlabel(param_name)\n",
    "            axes[i, 1].set_ylabel('Density')\n",
    "            axes[i, 1].legend()\n",
    "            axes[i, 1].grid(True, alpha=0.3)\n",
    "            \n",
    "            # 3. Autocorrelation (if requested)\n",
    "            if include_autocorr:\n",
    "                autocorr = self._compute_autocorrelation(post_burnin, max_lag=100)\n",
    "                lags = np.arange(len(autocorr))\n",
    "                \n",
    "                axes[i, 2].plot(lags, autocorr, color=color, linewidth=2)\n",
    "                axes[i, 2].axhline(0, color='black', linestyle='--', alpha=0.5)\n",
    "                axes[i, 2].axhline(0.1, color='red', linestyle='--', \n",
    "                                  alpha=0.7, label='10% threshold')\n",
    "                axes[i, 2].set_title(f'Autocorrelation: {param_name}')\n",
    "                axes[i, 2].set_xlabel('Lag')\n",
    "                axes[i, 2].set_ylabel('Autocorrelation')\n",
    "                axes[i, 2].legend()\n",
    "                axes[i, 2].grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        return fig, axes\n",
    "    \n",
    "    def plot_joint_distributions(self, samples, parameter_names, \n",
    "                                true_values=None, confidence_levels=[0.68, 0.95]):\n",
    "        \"\"\"Plot joint posterior distributions with confidence ellipses.\"\"\"\n",
    "        n_params = len(parameter_names)\n",
    "        \n",
    "        fig, axes = plt.subplots(n_params, n_params, figsize=(3*n_params, 3*n_params))\n",
    "        \n",
    "        for i in range(n_params):\n",
    "            for j in range(n_params):\n",
    "                if i == j:\n",
    "                    # Diagonal: marginal distributions\n",
    "                    axes[i, j].hist(samples[:, i], bins=30, density=True, \n",
    "                                   alpha=0.7, color=self.colors[i])\n",
    "                    axes[i, j].set_ylabel('Density')\n",
    "                    \n",
    "                    if true_values is not None:\n",
    "                        axes[i, j].axvline(true_values[i], color='green', \n",
    "                                          linestyle='-', linewidth=2)\n",
    "                    \n",
    "                elif i > j:\n",
    "                    # Lower triangle: scatter plots with confidence ellipses\n",
    "                    x_samples = samples[:, j]\n",
    "                    y_samples = samples[:, i]\n",
    "                    \n",
    "                    # Scatter plot (subsample for clarity)\n",
    "                    n_plot = min(1000, len(x_samples))\n",
    "                    idx = np.random.choice(len(x_samples), n_plot, replace=False)\n",
    "                    axes[i, j].scatter(x_samples[idx], y_samples[idx], \n",
    "                                      alpha=0.3, s=10, color=self.colors[0])\n",
    "                    \n",
    "                    # Confidence ellipses\n",
    "                    for conf, alpha in zip(confidence_levels, [0.3, 0.1]):\n",
    "                        ellipse = self._confidence_ellipse(x_samples, y_samples, \n",
    "                                                          confidence=conf)\n",
    "                        ellipse.set_alpha(alpha)\n",
    "                        ellipse.set_facecolor(self.colors[1])\n",
    "                        ellipse.set_edgecolor(self.colors[1])\n",
    "                        axes[i, j].add_patch(ellipse)\n",
    "                    \n",
    "                    if true_values is not None:\n",
    "                        axes[i, j].scatter(true_values[j], true_values[i], \n",
    "                                          color='green', s=100, marker='*', \n",
    "                                          zorder=5, label='True values')\n",
    "                    \n",
    "                    axes[i, j].set_xlabel(parameter_names[j])\n",
    "                    axes[i, j].set_ylabel(parameter_names[i])\n",
    "                    \n",
    "                else:\n",
    "                    # Upper triangle: correlation information\n",
    "                    corr = np.corrcoef(samples[:, i], samples[:, j])[0, 1]\n",
    "                    axes[i, j].text(0.5, 0.5, f'Ï = {corr:.3f}', \n",
    "                                   transform=axes[i, j].transAxes, \n",
    "                                   fontsize=16, ha='center', va='center',\n",
    "                                   bbox=dict(boxstyle=\"round,pad=0.3\", \n",
    "                                            facecolor='lightblue', alpha=0.7))\n",
    "                    axes[i, j].set_xlim([0, 1])\n",
    "                    axes[i, j].set_ylim([0, 1])\n",
    "                    axes[i, j].set_xticks([])\n",
    "                    axes[i, j].set_yticks([])\n",
    "                \n",
    "                # Set parameter names on edges\n",
    "                if i == n_params - 1:\n",
    "                    axes[i, j].set_xlabel(parameter_names[j])\n",
    "                if j == 0 and i > 0:\n",
    "                    axes[i, j].set_ylabel(parameter_names[i])\n",
    "                \n",
    "                axes[i, j].grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        return fig, axes\n",
    "    \n",
    "    def _compute_autocorrelation(self, x, max_lag=100):\n",
    "        \"\"\"Compute autocorrelation function.\"\"\"\n",
    "        n = len(x)\n",
    "        x_centered = x - np.mean(x)\n",
    "        autocorr = np.correlate(x_centered, x_centered, mode='full')\n",
    "        autocorr = autocorr[n-1:n-1+max_lag]\n",
    "        return autocorr / autocorr[0]\n",
    "    \n",
    "    def _confidence_ellipse(self, x, y, confidence=0.95):\n",
    "        \"\"\"Create confidence ellipse for 2D data.\"\"\"\n",
    "        from scipy.stats import chi2\n",
    "        \n",
    "        # Compute covariance matrix\n",
    "        cov = np.cov(x, y)\n",
    "        \n",
    "        # Eigendecomposition\n",
    "        eigenvals, eigenvecs = np.linalg.eigh(cov)\n",
    "        \n",
    "        # Compute ellipse parameters\n",
    "        angle = np.degrees(np.arctan2(eigenvecs[1, 0], eigenvecs[0, 0]))\n",
    "        \n",
    "        # Chi-square critical value for confidence level\n",
    "        chi2_val = chi2.ppf(confidence, df=2)\n",
    "        \n",
    "        # Ellipse width and height\n",
    "        width = 2 * np.sqrt(chi2_val * eigenvals[0])\n",
    "        height = 2 * np.sqrt(chi2_val * eigenvals[1])\n",
    "        \n",
    "        # Center\n",
    "        center = (np.mean(x), np.mean(y))\n",
    "        \n",
    "        return Ellipse(center, width, height, angle=angle)\n",
    "\n",
    "# Initialize Bayesian plotter\n",
    "bayes_plotter = BayesianPlotter(style='academic')\n",
    "print(\"âœ… Bayesian plotter initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic MCMC samples for demonstration\n",
    "def generate_mcmc_samples(n_samples=5000, n_params=3):\n",
    "    \"\"\"Generate realistic MCMC samples with correlations.\"\"\"\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # True parameter values\n",
    "    true_params = np.array([1.5, 2.0, 0.8][:n_params])\n",
    "    \n",
    "    # Create correlated samples\n",
    "    # Start with independent normal samples\n",
    "    samples = np.random.normal(0, 1, (n_samples, n_params))\n",
    "    \n",
    "    # Add correlations through linear transformation\n",
    "    if n_params >= 2:\n",
    "        # Correlation matrix (example)\n",
    "        L = np.array([[1.0, 0.0, 0.0],\n",
    "                     [0.3, 0.9, 0.0], \n",
    "                     [-0.2, 0.1, 0.8]])[:n_params, :n_params]\n",
    "        samples = samples @ L.T\n",
    "    \n",
    "    # Scale and shift to match target distribution\n",
    "    scales = np.array([0.2, 0.3, 0.15][:n_params])\n",
    "    samples = samples * scales + true_params\n",
    "    \n",
    "    # Add some burn-in behavior (initial bias)\n",
    "    burnin_length = 500\n",
    "    for i in range(burnin_length):\n",
    "        # Linear transition from biased to unbiased\n",
    "        bias_factor = (burnin_length - i) / burnin_length\n",
    "        bias = np.array([0.5, -0.3, 0.2][:n_params]) * bias_factor\n",
    "        samples[i] += bias\n",
    "    \n",
    "    return samples, true_params\n",
    "\n",
    "# Generate demonstration data\n",
    "mcmc_samples, true_params = generate_mcmc_samples(n_samples=5000, n_params=3)\n",
    "param_names = ['Îº (conductivity)', 'Ïƒ (source)', 'Î± (diffusivity)']\n",
    "\n",
    "print(f\"ðŸ“Š Generated MCMC samples:\")\n",
    "print(f\"   Samples: {mcmc_samples.shape[0]}\")\n",
    "print(f\"   Parameters: {mcmc_samples.shape[1]}\")\n",
    "print(f\"   True values: {true_params}\")\n",
    "print(f\"   Sample means: {np.mean(mcmc_samples[500:], axis=0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive MCMC diagnostics visualization\n",
    "print(\"ðŸŽ¨ MCMC Diagnostics Visualization Showcase\")\n",
    "\n",
    "# Create trace diagnostics plot\n",
    "fig, axes = bayes_plotter.plot_trace_diagnostics(\n",
    "    mcmc_samples, param_names, \n",
    "    true_values=true_params, \n",
    "    burnin=500,\n",
    "    include_autocorr=True\n",
    ")\n",
    "\n",
    "plt.suptitle('MCMC Trace Diagnostics', fontsize=20, y=0.98)\n",
    "plt.show()\n",
    "\n",
    "# Compute convergence statistics\n",
    "burnin = 500\n",
    "post_samples = mcmc_samples[burnin:]\n",
    "\n",
    "print(f\"\\nðŸ“ˆ Convergence Statistics (post burn-in):\")\n",
    "print(\"=\" * 60)\n",
    "for i, name in enumerate(param_names):\n",
    "    samples_i = post_samples[:, i]\n",
    "    \n",
    "    # Basic statistics\n",
    "    mean_val = np.mean(samples_i)\n",
    "    std_val = np.std(samples_i)\n",
    "    \n",
    "    # Effective sample size (simplified)\n",
    "    autocorr = bayes_plotter._compute_autocorrelation(samples_i, max_lag=100)\n",
    "    # Find where autocorr drops below 0.1\n",
    "    tau_int = 1.0\n",
    "    for lag in range(1, len(autocorr)):\n",
    "        if autocorr[lag] < 0.1:\n",
    "            break\n",
    "        tau_int += 2 * autocorr[lag]\n",
    "    \n",
    "    ess = len(samples_i) / tau_int\n",
    "    \n",
    "    print(f\"   {name}:\")\n",
    "    print(f\"      Mean: {mean_val:.4f} Â± {std_val:.4f}\")\n",
    "    print(f\"      True: {true_params[i]:.4f}\")\n",
    "    print(f\"      Bias: {mean_val - true_params[i]:.4f}\")\n",
    "    print(f\"      ESS:  {ess:.0f} / {len(samples_i)} ({ess/len(samples_i)*100:.1f}%)\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joint distribution analysis\n",
    "print(\"ðŸŽ¨ Joint Distribution Visualization\")\n",
    "\n",
    "# Create joint distribution plot\n",
    "fig, axes = bayes_plotter.plot_joint_distributions(\n",
    "    post_samples, param_names, \n",
    "    true_values=true_params, \n",
    "    confidence_levels=[0.68, 0.95]\n",
    ")\n",
    "\n",
    "plt.suptitle('Joint Posterior Distributions', fontsize=18, y=0.95)\n",
    "plt.show()\n",
    "\n",
    "# Correlation analysis\n",
    "print(f\"\\nðŸ“Š Parameter Correlations:\")\n",
    "print(\"=\" * 40)\n",
    "corr_matrix = np.corrcoef(post_samples.T)\n",
    "\n",
    "for i in range(len(param_names)):\n",
    "    for j in range(i+1, len(param_names)):\n",
    "        corr = corr_matrix[i, j]\n",
    "        print(f\"   {param_names[i][:10]:<10} - {param_names[j][:10]:<10}: {corr:6.3f}\")\n",
    "\n",
    "# Covariance ellipse areas (measure of uncertainty)\n",
    "print(f\"\\nðŸ“ Uncertainty Measures:\")\n",
    "print(\"=\" * 30)\n",
    "for i in range(len(param_names)):\n",
    "    std_i = np.std(post_samples[:, i])\n",
    "    print(f\"   {param_names[i]:<20}: Ïƒ = {std_i:.4f}\")\n",
    "\n",
    "# Overall covariance determinant (total uncertainty volume)\n",
    "cov_det = np.linalg.det(np.cov(post_samples.T))\n",
    "print(f\"\\n   Total uncertainty volume: {cov_det:.2e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: Uncertainty Visualization\n",
    "\n",
    "Advanced visualization of uncertainty bounds and prediction intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create uncertainty visualization class\n",
    "class UncertaintyPlotter:\n",
    "    \"\"\"Professional uncertainty quantification visualization.\"\"\"\n",
    "    \n",
    "    def __init__(self, style='academic'):\n",
    "        self.style = style\n",
    "        self.colors = academic_colors\n",
    "        \n",
    "    def plot_prediction_bands(self, x, y_samples, x_new=None, \n",
    "                            confidence_levels=[0.68, 0.95],\n",
    "                            title=\"Prediction with Uncertainty\",\n",
    "                            observations=None, true_function=None):\n",
    "        \"\"\"Plot prediction with uncertainty bands.\"\"\"\n",
    "        fig, ax = plt.subplots(figsize=(12, 8))\n",
    "        \n",
    "        if x_new is None:\n",
    "            x_new = x\n",
    "        \n",
    "        # Compute percentiles for confidence bands\n",
    "        mean_pred = np.mean(y_samples, axis=0)\n",
    "        \n",
    "        # Plot confidence bands\n",
    "        colors_alpha = [(0.3, 0.15), (0.6, 0.25)]  # (color_alpha, edge_alpha)\n",
    "        \n",
    "        for i, (conf, (c_alpha, e_alpha)) in enumerate(zip(confidence_levels, colors_alpha)):\n",
    "            lower_p = (1 - conf) / 2 * 100\n",
    "            upper_p = (1 + conf) / 2 * 100\n",
    "            \n",
    "            lower_bound = np.percentile(y_samples, lower_p, axis=0)\n",
    "            upper_bound = np.percentile(y_samples, upper_p, axis=0)\n",
    "            \n",
    "            ax.fill_between(x_new, lower_bound, upper_bound, \n",
    "                          alpha=c_alpha, color=self.colors[i+1], \n",
    "                          label=f'{conf*100:.0f}% confidence')\n",
    "            ax.plot(x_new, lower_bound, color=self.colors[i+1], \n",
    "                   alpha=e_alpha, linewidth=1)\n",
    "            ax.plot(x_new, upper_bound, color=self.colors[i+1], \n",
    "                   alpha=e_alpha, linewidth=1)\n",
    "        \n",
    "        # Plot mean prediction\n",
    "        ax.plot(x_new, mean_pred, color=self.colors[0], linewidth=3, \n",
    "               label='Mean prediction')\n",
    "        \n",
    "        # Plot true function if provided\n",
    "        if true_function is not None:\n",
    "            ax.plot(x_new, true_function, color='green', linewidth=2, \n",
    "                   linestyle='--', label='True function')\n",
    "        \n",
    "        # Plot observations if provided\n",
    "        if observations is not None:\n",
    "            obs_x, obs_y = observations\n",
    "            ax.scatter(obs_x, obs_y, color='red', s=100, zorder=5, \n",
    "                      label='Observations', marker='o', edgecolor='darkred')\n",
    "        \n",
    "        ax.set_xlabel('x')\n",
    "        ax.set_ylabel('y')\n",
    "        ax.set_title(title)\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        return fig, ax\n",
    "    \n",
    "    def plot_uncertainty_evolution(self, x, uncertainty_samples, \n",
    "                                 uncertainty_type=\"std\",\n",
    "                                 title=\"Uncertainty Evolution\"):\n",
    "        \"\"\"Plot how uncertainty evolves across domain.\"\"\"\n",
    "        fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10))\n",
    "        \n",
    "        if uncertainty_type == \"std\":\n",
    "            uncertainty = np.std(uncertainty_samples, axis=0)\n",
    "            y_label = \"Standard Deviation\"\n",
    "        elif uncertainty_type == \"var\":\n",
    "            uncertainty = np.var(uncertainty_samples, axis=0)\n",
    "            y_label = \"Variance\"\n",
    "        elif uncertainty_type == \"iqr\":\n",
    "            uncertainty = (np.percentile(uncertainty_samples, 75, axis=0) - \n",
    "                          np.percentile(uncertainty_samples, 25, axis=0))\n",
    "            y_label = \"Interquartile Range\"\n",
    "        \n",
    "        # Plot uncertainty\n",
    "        ax1.plot(x, uncertainty, color=self.colors[0], linewidth=3)\n",
    "        ax1.fill_between(x, 0, uncertainty, alpha=0.3, color=self.colors[0])\n",
    "        ax1.set_xlabel('Position')\n",
    "        ax1.set_ylabel(y_label)\n",
    "        ax1.set_title(f'{title} - {y_label}')\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Plot coefficient of variation\n",
    "        mean_vals = np.mean(uncertainty_samples, axis=0)\n",
    "        cv = np.std(uncertainty_samples, axis=0) / (np.abs(mean_vals) + 1e-10)\n",
    "        \n",
    "        ax2.plot(x, cv, color=self.colors[1], linewidth=3)\n",
    "        ax2.fill_between(x, 0, cv, alpha=0.3, color=self.colors[1])\n",
    "        ax2.set_xlabel('Position')\n",
    "        ax2.set_ylabel('Coefficient of Variation')\n",
    "        ax2.set_title('Relative Uncertainty (CV = Ïƒ/|Î¼|)')\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        return fig, (ax1, ax2)\n",
    "    \n",
    "    def plot_certified_vs_bayesian(self, parameter_estimates, \n",
    "                                  certified_bounds, bayesian_intervals,\n",
    "                                  parameter_names, true_values=None):\n",
    "        \"\"\"Compare certified bounds with Bayesian credible intervals.\"\"\"\n",
    "        n_params = len(parameter_names)\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(12, 8))\n",
    "        \n",
    "        y_positions = np.arange(n_params)\n",
    "        bar_height = 0.35\n",
    "        \n",
    "        # Plot Bayesian intervals\n",
    "        bayes_widths = []\n",
    "        for i, (lower, upper) in enumerate(bayesian_intervals):\n",
    "            width = upper - lower\n",
    "            bayes_widths.append(width)\n",
    "            \n",
    "            # Error bar for Bayesian CI\n",
    "            ax.errorbar(parameter_estimates[i], y_positions[i] - bar_height/2, \n",
    "                       xerr=[[parameter_estimates[i] - lower], [upper - parameter_estimates[i]]], \n",
    "                       fmt='o', color=self.colors[0], markersize=8, \n",
    "                       capsize=5, capthick=2, linewidth=2, \n",
    "                       label='Bayesian 95% CI' if i == 0 else '')\n",
    "        \n",
    "        # Plot certified bounds\n",
    "        cert_widths = []\n",
    "        for i, (lower, upper) in enumerate(certified_bounds):\n",
    "            width = upper - lower\n",
    "            cert_widths.append(width)\n",
    "            \n",
    "            # Error bar for certified bounds\n",
    "            center = (lower + upper) / 2\n",
    "            ax.errorbar(center, y_positions[i] + bar_height/2, \n",
    "                       xerr=[[center - lower], [upper - center]], \n",
    "                       fmt='s', color=self.colors[1], markersize=8, \n",
    "                       capsize=5, capthick=2, linewidth=2,\n",
    "                       label='Certified bounds' if i == 0 else '')\n",
    "        \n",
    "        # Plot true values if provided\n",
    "        if true_values is not None:\n",
    "            ax.scatter(true_values, y_positions, color='green', \n",
    "                      s=150, marker='*', zorder=5, label='True values')\n",
    "        \n",
    "        ax.set_yticks(y_positions)\n",
    "        ax.set_yticklabels(parameter_names)\n",
    "        ax.set_xlabel('Parameter Value')\n",
    "        ax.set_title('Certified Bounds vs Bayesian Credible Intervals')\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Add width comparison text\n",
    "        for i in range(n_params):\n",
    "            bayes_w = bayes_widths[i]\n",
    "            cert_w = cert_widths[i]\n",
    "            ratio = cert_w / bayes_w\n",
    "            \n",
    "            ax.text(0.02, 0.95 - i*0.15, \n",
    "                   f'{parameter_names[i]}: Cert/Bayes = {ratio:.2f}x',\n",
    "                   transform=ax.transAxes, fontsize=10,\n",
    "                   bbox=dict(boxstyle=\"round,pad=0.3\", facecolor='white', alpha=0.8))\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        return fig, ax\n",
    "\n",
    "# Initialize uncertainty plotter\n",
    "uncertainty_plotter = UncertaintyPlotter(style='academic')\n",
    "print(\"âœ… Uncertainty plotter initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic prediction data for uncertainty visualization\n",
    "def generate_prediction_samples(n_samples=200, n_points=100):\n",
    "    \"\"\"Generate realistic prediction samples with uncertainty.\"\"\"\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # Domain\n",
    "    x = np.linspace(0, 2*np.pi, n_points)\n",
    "    \n",
    "    # True underlying function\n",
    "    def true_function(x):\n",
    "        return np.sin(x) + 0.2 * np.sin(5*x) * np.exp(-0.3*x)\n",
    "    \n",
    "    y_true = true_function(x)\n",
    "    \n",
    "    # Generate prediction samples with different uncertainties\n",
    "    y_samples = np.zeros((n_samples, n_points))\n",
    "    \n",
    "    for i in range(n_samples):\n",
    "        # Parameter uncertainty (affects amplitude and phase)\n",
    "        amp_noise = np.random.normal(1.0, 0.1)\n",
    "        phase_noise = np.random.normal(0.0, 0.05)\n",
    "        \n",
    "        # Model uncertainty (additional terms)\n",
    "        model_noise = 0.05 * np.random.normal(0, 1, n_points)\n",
    "        \n",
    "        # Prediction with uncertainty\n",
    "        y_pred = amp_noise * true_function(x + phase_noise) + model_noise\n",
    "        \n",
    "        # Add spatially varying noise (higher uncertainty at boundaries)\n",
    "        spatial_noise_std = 0.02 * (1 + 2 * np.exp(-2*(x - np.pi)**2))\n",
    "        spatial_noise = np.random.normal(0, spatial_noise_std)\n",
    "        \n",
    "        y_samples[i] = y_pred + spatial_noise\n",
    "    \n",
    "    # Generate some observations\n",
    "    obs_x = np.array([0.5, 1.5, 2.5, 4.0, 5.5])\n",
    "    obs_y = true_function(obs_x) + np.random.normal(0, 0.05, len(obs_x))\n",
    "    \n",
    "    return x, y_samples, y_true, (obs_x, obs_y)\n",
    "\n",
    "# Generate prediction data\n",
    "x_pred, y_pred_samples, y_true_func, observations = generate_prediction_samples()\n",
    "\n",
    "print(f\"ðŸ“Š Generated prediction data:\")\n",
    "print(f\"   Domain points: {len(x_pred)}\")\n",
    "print(f\"   Prediction samples: {y_pred_samples.shape[0]}\")\n",
    "print(f\"   Observations: {len(observations[0])}\")\n",
    "print(f\"   Prediction range: [{np.min(y_pred_samples):.3f}, {np.max(y_pred_samples):.3f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Showcase prediction uncertainty visualization\n",
    "print(\"ðŸŽ¨ Prediction Uncertainty Visualization\")\n",
    "\n",
    "# Create prediction bands plot\n",
    "fig, ax = uncertainty_plotter.plot_prediction_bands(\n",
    "    x_pred, y_pred_samples, \n",
    "    confidence_levels=[0.68, 0.95],\n",
    "    title=\"PDE Solution Prediction with Uncertainty Bands\",\n",
    "    observations=observations,\n",
    "    true_function=y_true_func\n",
    ")\n",
    "\n",
    "# Add additional annotations\n",
    "ax.annotate('High uncertainty\\nregion', \n",
    "           xy=(np.pi, np.max(y_true_func)), xytext=(np.pi+1, np.max(y_true_func)+0.3),\n",
    "           arrowprops=dict(arrowstyle='->', color='red', alpha=0.7),\n",
    "           bbox=dict(boxstyle=\"round,pad=0.3\", facecolor='yellow', alpha=0.7),\n",
    "           fontsize=10)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Compute prediction statistics\n",
    "mean_pred = np.mean(y_pred_samples, axis=0)\n",
    "std_pred = np.std(y_pred_samples, axis=0)\n",
    "\n",
    "# Coverage analysis\n",
    "lower_68 = np.percentile(y_pred_samples, 16, axis=0)\n",
    "upper_68 = np.percentile(y_pred_samples, 84, axis=0)\n",
    "lower_95 = np.percentile(y_pred_samples, 2.5, axis=0)\n",
    "upper_95 = np.percentile(y_pred_samples, 97.5, axis=0)\n",
    "\n",
    "# Check coverage of true function\n",
    "coverage_68 = np.mean((y_true_func >= lower_68) & (y_true_func <= upper_68))\n",
    "coverage_95 = np.mean((y_true_func >= lower_95) & (y_true_func <= upper_95))\n",
    "\n",
    "print(f\"\\nðŸ“ˆ Prediction Quality:\")\n",
    "print(f\"   68% band coverage: {coverage_68*100:.1f}% (expected: 68%)\")\n",
    "print(f\"   95% band coverage: {coverage_95*100:.1f}% (expected: 95%)\")\n",
    "print(f\"   Mean absolute error: {np.mean(np.abs(mean_pred - y_true_func)):.4f}\")\n",
    "print(f\"   Mean prediction std: {np.mean(std_pred):.4f}\")\n",
    "print(f\"   Max prediction std: {np.max(std_pred):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncertainty evolution analysis\n",
    "print(\"ðŸŽ¨ Uncertainty Evolution Analysis\")\n",
    "\n",
    "# Plot uncertainty evolution\n",
    "fig, (ax1, ax2) = uncertainty_plotter.plot_uncertainty_evolution(\n",
    "    x_pred, y_pred_samples, \n",
    "    uncertainty_type=\"std\",\n",
    "    title=\"Spatial Uncertainty Evolution\"\n",
    ")\n",
    "\n",
    "# Add markers for observation locations\n",
    "obs_x, _ = observations\n",
    "for obs_xi in obs_x:\n",
    "    ax1.axvline(obs_xi, color='red', linestyle=':', alpha=0.7, linewidth=1)\n",
    "    ax2.axvline(obs_xi, color='red', linestyle=':', alpha=0.7, linewidth=1)\n",
    "\n",
    "ax1.text(0.02, 0.95, 'Red lines: observations', transform=ax1.transAxes,\n",
    "         bbox=dict(boxstyle=\"round,pad=0.3\", facecolor='white', alpha=0.8))\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Analyze uncertainty patterns\n",
    "std_vals = np.std(y_pred_samples, axis=0)\n",
    "cv_vals = std_vals / (np.abs(np.mean(y_pred_samples, axis=0)) + 1e-10)\n",
    "\n",
    "print(f\"\\nðŸ“Š Uncertainty Pattern Analysis:\")\n",
    "print(f\"   Uncertainty range: [{np.min(std_vals):.4f}, {np.max(std_vals):.4f}]\")\n",
    "print(f\"   Uncertainty peaks at: x = {x_pred[np.argmax(std_vals)]:.3f}\")\n",
    "print(f\"   Uncertainty minimized at: x = {x_pred[np.argmin(std_vals)]:.3f}\")\n",
    "print(f\"   Mean CV: {np.mean(cv_vals):.3f} (lower is better)\")\n",
    "print(f\"   Max CV: {np.max(cv_vals):.3f}\")\n",
    "\n",
    "# Distance to nearest observation analysis\n",
    "obs_x_array = np.array(observations[0])\n",
    "min_distances = np.array([np.min(np.abs(xi - obs_x_array)) for xi in x_pred])\n",
    "correlation = np.corrcoef(min_distances, std_vals)[0, 1]\n",
    "\n",
    "print(f\"\\nðŸ” Observation Impact:\")\n",
    "print(f\"   Correlation (distance to obs, uncertainty): {correlation:.3f}\")\n",
    "if correlation > 0.3:\n",
    "    print(f\"   âœ… Strong positive correlation: uncertainty increases with distance\")\n",
    "elif correlation < -0.3:\n",
    "    print(f\"   âš ï¸ Negative correlation: unexpected pattern\")\n",
    "else:\n",
    "    print(f\"   â„¹ï¸ Weak correlation: other factors dominate uncertainty\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Certified vs Bayesian comparison visualization\n",
    "print(\"ðŸŽ¨ Certified vs Bayesian Uncertainty Comparison\")\n",
    "\n",
    "# Generate synthetic comparison data\n",
    "np.random.seed(42)\n",
    "param_names_comp = ['Îº (conductivity)', 'Ïƒ (source)', 'Î± (diffusivity)']\n",
    "true_vals_comp = np.array([1.5, 2.0, 0.8])\n",
    "\n",
    "# Bayesian estimates (from MCMC)\n",
    "bayes_estimates = np.array([1.48, 2.03, 0.79])\n",
    "\n",
    "# Bayesian 95% credible intervals\n",
    "bayes_intervals = [\n",
    "    (1.35, 1.61),  # Îº\n",
    "    (1.82, 2.24),  # Ïƒ  \n",
    "    (0.73, 0.85)   # Î±\n",
    "]\n",
    "\n",
    "# Certified bounds (typically wider)\n",
    "certified_bounds = [\n",
    "    (1.28, 1.72),  # Îº - wider than Bayesian\n",
    "    (1.75, 2.31),  # Ïƒ - wider than Bayesian\n",
    "    (0.70, 0.88)   # Î± - wider than Bayesian\n",
    "]\n",
    "\n",
    "# Create comparison plot\n",
    "fig, ax = uncertainty_plotter.plot_certified_vs_bayesian(\n",
    "    bayes_estimates, certified_bounds, bayes_intervals,\n",
    "    param_names_comp, true_values=true_vals_comp\n",
    ")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Detailed comparison analysis\n",
    "print(f\"\\nðŸ“Š Detailed Uncertainty Comparison:\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"{'Parameter':<15} {'Bayes Width':<12} {'Cert Width':<12} {'Ratio':<8} {'Coverage':<15}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for i, name in enumerate(param_names_comp):\n",
    "    bayes_w = bayes_intervals[i][1] - bayes_intervals[i][0]\n",
    "    cert_w = certified_bounds[i][1] - certified_bounds[i][0]\n",
    "    ratio = cert_w / bayes_w\n",
    "    \n",
    "    # Check coverage\n",
    "    true_val = true_vals_comp[i]\n",
    "    bayes_covers = bayes_intervals[i][0] <= true_val <= bayes_intervals[i][1]\n",
    "    cert_covers = certified_bounds[i][0] <= true_val <= certified_bounds[i][1]\n",
    "    \n",
    "    coverage_str = f\"B:{'âœ“' if bayes_covers else 'âœ—'} C:{'âœ“' if cert_covers else 'âœ—'}\"\n",
    "    \n",
    "    print(f\"{name[:14]:<15} {bayes_w:<12.3f} {cert_w:<12.3f} {ratio:<8.2f} {coverage_str:<15}\")\n",
    "\n",
    "print(f\"\\nðŸ’¡ Key Insights:\")\n",
    "print(f\"   â€¢ Certified bounds are typically 1.1-1.3x wider than Bayesian\")\n",
    "print(f\"   â€¢ Both methods should cover true values for valid inference\")\n",
    "print(f\"   â€¢ Certified bounds provide mathematical guarantees\")\n",
    "print(f\"   â€¢ Bayesian intervals assume correct model specification\")\n",
    "print(f\"   â€¢ Use both for comprehensive uncertainty quantification!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4: Publication-Quality Figures\n",
    "\n",
    "Professional academic-style visualizations ready for publication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create publication-quality figure class\n",
    "class PublicationFigures:\n",
    "    \"\"\"Generate publication-ready academic figures.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Set academic publication style\n",
    "        self.pub_style = {\n",
    "            'figure.figsize': (10, 8),\n",
    "            'font.size': 14,\n",
    "            'axes.labelsize': 16,\n",
    "            'axes.titlesize': 18,\n",
    "            'xtick.labelsize': 14,\n",
    "            'ytick.labelsize': 14,\n",
    "            'legend.fontsize': 14,\n",
    "            'lines.linewidth': 2.5,\n",
    "            'lines.markersize': 8,\n",
    "            'axes.linewidth': 1.5,\n",
    "            'grid.linewidth': 0.8,\n",
    "            'xtick.major.width': 1.5,\n",
    "            'ytick.major.width': 1.5,\n",
    "            'xtick.minor.width': 1.0,\n",
    "            'ytick.minor.width': 1.0,\n",
    "            'savefig.dpi': 300,\n",
    "            'savefig.bbox': 'tight',\n",
    "            'savefig.pad_inches': 0.1\n",
    "        }\n",
    "        \n",
    "        # Academic color scheme (colorblind-friendly)\n",
    "        self.academic_colors = {\n",
    "            'blue': '#1f77b4',\n",
    "            'orange': '#ff7f0e', \n",
    "            'green': '#2ca02c',\n",
    "            'red': '#d62728',\n",
    "            'purple': '#9467bd',\n",
    "            'brown': '#8c564b',\n",
    "            'pink': '#e377c2',\n",
    "            'gray': '#7f7f7f',\n",
    "            'olive': '#bcbd22',\n",
    "            'cyan': '#17becf'\n",
    "        }\n",
    "        \n",
    "    def apply_style(self):\n",
    "        \"\"\"Apply publication style.\"\"\"\n",
    "        plt.rcParams.update(self.pub_style)\n",
    "        \n",
    "    def create_figure_grid(self, n_rows, n_cols, figsize=None):\n",
    "        \"\"\"Create publication-quality figure grid.\"\"\"\n",
    "        if figsize is None:\n",
    "            figsize = (5*n_cols, 4*n_rows)\n",
    "        \n",
    "        fig, axes = plt.subplots(n_rows, n_cols, figsize=figsize)\n",
    "        \n",
    "        # Ensure axes is always 2D array\n",
    "        if n_rows == 1 and n_cols == 1:\n",
    "            axes = np.array([[axes]])\n",
    "        elif n_rows == 1:\n",
    "            axes = axes.reshape(1, -1)\n",
    "        elif n_cols == 1:\n",
    "            axes = axes.reshape(-1, 1)\n",
    "        \n",
    "        return fig, axes\n",
    "    \n",
    "    def save_figure(self, fig, filename, dpi=300):\n",
    "        \"\"\"Save figure in multiple formats for publication.\"\"\"\n",
    "        formats = ['png', 'pdf', 'eps']\n",
    "        \n",
    "        for fmt in formats:\n",
    "            fig.savefig(f\"{filename}.{fmt}\", dpi=dpi, bbox_inches='tight', \n",
    "                       pad_inches=0.1, format=fmt)\n",
    "        \n",
    "        print(f\"ðŸ“„ Saved publication figure: {filename}.{{png,pdf,eps}}\")\n",
    "\n",
    "# Initialize publication figure generator\n",
    "pub_figs = PublicationFigures()\n",
    "pub_figs.apply_style()\n",
    "\n",
    "print(\"âœ… Publication figure generator initialized\")\n",
    "print(\"ðŸ“ Academic style applied\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive publication figure showcasing the framework\n",
    "print(\"ðŸŽ¨ Creating Publication-Quality Framework Showcase\")\n",
    "\n",
    "# Create main showcase figure\n",
    "fig = plt.figure(figsize=(16, 12))\n",
    "\n",
    "# Create complex subplot layout\n",
    "gs = fig.add_gridspec(3, 4, height_ratios=[1, 1, 1], width_ratios=[1, 1, 1, 1],\n",
    "                     hspace=0.3, wspace=0.4)\n",
    "\n",
    "# Panel A: PDE Solution (2D)\n",
    "ax_a = fig.add_subplot(gs[0, :2])\n",
    "sol_2d = demo_solutions['2d']\n",
    "X, Y, U = sol_2d['X'], sol_2d['Y'], sol_2d['U']\n",
    "contourf = ax_a.contourf(X, Y, U, levels=20, cmap='viridis')\n",
    "contour = ax_a.contour(X, Y, U, levels=10, colors='white', alpha=0.6, linewidths=1)\n",
    "cbar_a = plt.colorbar(contourf, ax=ax_a)\n",
    "cbar_a.set_label('Solution u(x,y)', fontsize=14)\n",
    "ax_a.set_xlabel('x')\n",
    "ax_a.set_ylabel('y')\n",
    "ax_a.set_title('(A) PDE Solution Field', fontweight='bold', fontsize=16)\n",
    "ax_a.text(-0.15, 1.05, 'A', transform=ax_a.transAxes, fontsize=20, fontweight='bold')\n",
    "\n",
    "# Panel B: Observations and Uncertainty\n",
    "ax_b = fig.add_subplot(gs[0, 2:])\n",
    "sol_1d = demo_solutions['1d']\n",
    "ax_b.plot(sol_1d['x'], sol_1d['u'], color=pub_figs.academic_colors['blue'], \n",
    "         linewidth=3, label='PDE Solution')\n",
    "obs_x, obs_u = sol_1d['observations']\n",
    "ax_b.scatter(obs_x, obs_u, color=pub_figs.academic_colors['red'], s=100, \n",
    "           zorder=5, label='Observations', edgecolor='darkred', linewidth=1.5)\n",
    "# Add error bars to observations\n",
    "obs_errors = 0.02 * np.ones_like(obs_u)\n",
    "ax_b.errorbar(obs_x, obs_u, yerr=obs_errors, fmt='none', \n",
    "             color=pub_figs.academic_colors['red'], capsize=4, capthick=2)\n",
    "ax_b.set_xlabel('Position x')\n",
    "ax_b.set_ylabel('Temperature u(x)')\n",
    "ax_b.set_title('(B) Forward Problem & Data', fontweight='bold', fontsize=16)\n",
    "ax_b.legend()\n",
    "ax_b.grid(True, alpha=0.3)\n",
    "ax_b.text(-0.15, 1.05, 'B', transform=ax_b.transAxes, fontsize=20, fontweight='bold')\n",
    "\n",
    "# Panel C: MCMC Traces\n",
    "ax_c1 = fig.add_subplot(gs[1, 0])\n",
    "ax_c2 = fig.add_subplot(gs[1, 1])\n",
    "\n",
    "# Use post-burnin samples\n",
    "post_samples = mcmc_samples[500:]\n",
    "\n",
    "# Parameter 1 trace\n",
    "ax_c1.plot(post_samples[:1000, 0], color=pub_figs.academic_colors['blue'], alpha=0.8)\n",
    "ax_c1.axhline(true_params[0], color=pub_figs.academic_colors['green'], \n",
    "             linestyle='--', linewidth=2, label='True value')\n",
    "ax_c1.set_xlabel('Iteration')\n",
    "ax_c1.set_ylabel('Îº (conductivity)')\n",
    "ax_c1.set_title('(Câ‚) MCMC Trace: Îº', fontweight='bold', fontsize=14)\n",
    "ax_c1.grid(True, alpha=0.3)\n",
    "ax_c1.text(-0.2, 1.05, 'Câ‚', transform=ax_c1.transAxes, fontsize=16, fontweight='bold')\n",
    "\n",
    "# Parameter 2 trace  \n",
    "ax_c2.plot(post_samples[:1000, 1], color=pub_figs.academic_colors['orange'], alpha=0.8)\n",
    "ax_c2.axhline(true_params[1], color=pub_figs.academic_colors['green'], \n",
    "             linestyle='--', linewidth=2, label='True value')\n",
    "ax_c2.set_xlabel('Iteration')\n",
    "ax_c2.set_ylabel('Ïƒ (source)')\n",
    "ax_c2.set_title('(Câ‚‚) MCMC Trace: Ïƒ', fontweight='bold', fontsize=14)\n",
    "ax_c2.grid(True, alpha=0.3)\n",
    "ax_c2.text(-0.2, 1.05, 'Câ‚‚', transform=ax_c2.transAxes, fontsize=16, fontweight='bold')\n",
    "\n",
    "# Panel D: Joint Distribution\n",
    "ax_d = fig.add_subplot(gs[1, 2:])\n",
    "# Scatter plot of posterior samples\n",
    "n_plot = 1000\n",
    "idx = np.random.choice(len(post_samples), n_plot, replace=False)\n",
    "ax_d.scatter(post_samples[idx, 0], post_samples[idx, 1], \n",
    "           alpha=0.4, s=20, color=pub_figs.academic_colors['purple'])\n",
    "\n",
    "# Add confidence ellipses\n",
    "def confidence_ellipse(x, y, ax, confidence=0.95, **kwargs):\n",
    "    from scipy.stats import chi2\n",
    "    cov = np.cov(x, y)\n",
    "    eigenvals, eigenvecs = np.linalg.eigh(cov)\n",
    "    angle = np.degrees(np.arctan2(eigenvecs[1, 0], eigenvecs[0, 0]))\n",
    "    chi2_val = chi2.ppf(confidence, df=2)\n",
    "    width = 2 * np.sqrt(chi2_val * eigenvals[0])\n",
    "    height = 2 * np.sqrt(chi2_val * eigenvals[1])\n",
    "    center = (np.mean(x), np.mean(y))\n",
    "    ellipse = Ellipse(center, width, height, angle=angle, **kwargs)\n",
    "    ax.add_patch(ellipse)\n",
    "    return ellipse\n",
    "\n",
    "# 95% confidence ellipse\n",
    "ellipse_95 = confidence_ellipse(post_samples[:, 0], post_samples[:, 1], ax_d, \n",
    "                               confidence=0.95, alpha=0.2, \n",
    "                               facecolor=pub_figs.academic_colors['blue'], \n",
    "                               edgecolor=pub_figs.academic_colors['blue'])\n",
    "\n",
    "# True values\n",
    "ax_d.scatter(true_params[0], true_params[1], color=pub_figs.academic_colors['green'], \n",
    "           s=150, marker='*', zorder=5, label='True values', edgecolor='darkgreen')\n",
    "\n",
    "ax_d.set_xlabel('Îº (conductivity)')\n",
    "ax_d.set_ylabel('Ïƒ (source)')\n",
    "ax_d.set_title('(D) Joint Posterior Distribution', fontweight='bold', fontsize=16)\n",
    "ax_d.legend()\n",
    "ax_d.grid(True, alpha=0.3)\n",
    "ax_d.text(-0.15, 1.05, 'D', transform=ax_d.transAxes, fontsize=20, fontweight='bold')\n",
    "\n",
    "# Panel E: Uncertainty Quantification Comparison\n",
    "ax_e = fig.add_subplot(gs[2, :2])\n",
    "\n",
    "# Comparison data\n",
    "methods = ['True', 'Bayesian\\n(Mean)', 'Certified\\nBounds']\n",
    "kappa_vals = [true_params[0], np.mean(post_samples[:, 0]), \n",
    "              (1.28 + 1.72)/2]  # Certified bound center\n",
    "kappa_errs = [0, np.std(post_samples[:, 0]), (1.72 - 1.28)/2]  # Half-widths\n",
    "\n",
    "colors_e = [pub_figs.academic_colors['green'], pub_figs.academic_colors['blue'], \n",
    "           pub_figs.academic_colors['red']]\n",
    "\n",
    "bars = ax_e.bar(methods, kappa_vals, yerr=kappa_errs, \n",
    "               color=colors_e, alpha=0.7, capsize=5, \n",
    "               error_kw={'linewidth': 2, 'capthick': 2})\n",
    "\n",
    "ax_e.set_ylabel('Îº (conductivity)')\n",
    "ax_e.set_title('(E) Uncertainty Quantification Methods', fontweight='bold', fontsize=16)\n",
    "ax_e.grid(True, alpha=0.3, axis='y')\n",
    "ax_e.text(-0.15, 1.05, 'E', transform=ax_e.transAxes, fontsize=20, fontweight='bold')\n",
    "\n",
    "# Add text annotations\n",
    "for i, (bar, val, err) in enumerate(zip(bars, kappa_vals, kappa_errs)):\n",
    "    if err > 0:\n",
    "        ax_e.text(bar.get_x() + bar.get_width()/2, val + err + 0.02,\n",
    "                 f'{val:.3f}Â±{err:.3f}', ha='center', va='bottom', fontsize=11)\n",
    "    else:\n",
    "        ax_e.text(bar.get_x() + bar.get_width()/2, val + 0.02,\n",
    "                 f'{val:.3f}', ha='center', va='bottom', fontsize=11)\n",
    "\n",
    "# Panel F: Model Performance\n",
    "ax_f = fig.add_subplot(gs[2, 2:])\n",
    "\n",
    "# Performance metrics\n",
    "metrics = ['Coverage\\n(68%)', 'Coverage\\n(95%)', 'RMSE', 'Log\\nLikelihood']\n",
    "bayesian_scores = [0.72, 0.94, 0.023, -25.3]  # Example scores\n",
    "certified_scores = [0.68, 0.95, 0.028, np.nan]  # Certified doesn't have likelihood\n",
    "\n",
    "x_pos = np.arange(len(metrics))\n",
    "width = 0.35\n",
    "\n",
    "# Handle NaN values\n",
    "bayes_mask = ~np.isnan(bayesian_scores)\n",
    "cert_mask = ~np.isnan(certified_scores)\n",
    "\n",
    "ax_f.bar(x_pos[bayes_mask] - width/2, np.array(bayesian_scores)[bayes_mask], \n",
    "        width, label='Bayesian', color=pub_figs.academic_colors['blue'], alpha=0.7)\n",
    "ax_f.bar(x_pos[cert_mask] + width/2, np.array(certified_scores)[cert_mask], \n",
    "        width, label='Certified', color=pub_figs.academic_colors['red'], alpha=0.7)\n",
    "\n",
    "ax_f.set_xlabel('Performance Metrics')\n",
    "ax_f.set_ylabel('Score')\n",
    "ax_f.set_title('(F) Method Performance Comparison', fontweight='bold', fontsize=16)\n",
    "ax_f.set_xticks(x_pos)\n",
    "ax_f.set_xticklabels(metrics)\n",
    "ax_f.legend()\n",
    "ax_f.grid(True, alpha=0.3, axis='y')\n",
    "ax_f.text(-0.15, 1.05, 'F', transform=ax_f.transAxes, fontsize=20, fontweight='bold')\n",
    "\n",
    "# Overall title\n",
    "fig.suptitle('Bayesian PDE Inverse Problems with Certified Uncertainty Quantification', \n",
    "            fontsize=20, fontweight='bold', y=0.95)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ… Publication-quality showcase figure created!\")\n",
    "print(\"ðŸ“Š Figure includes 6 panels covering the complete framework\")\n",
    "print(\"ðŸ“„ Ready for academic publication or presentation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Best Practices\n",
    "\n",
    "### Visualization Guidelines:\n",
    "\n",
    "1. **Clarity First**: Use clear labels, legends, and titles\n",
    "2. **Color Accessibility**: Choose colorblind-friendly palettes\n",
    "3. **Consistent Styling**: Maintain uniform appearance across figures\n",
    "4. **Information Density**: Balance detail with readability\n",
    "5. **Context**: Always provide sufficient context and interpretation\n",
    "\n",
    "### Publication Standards:\n",
    "\n",
    "- **DPI**: 300+ for print, 150+ for web\n",
    "- **Fonts**: Clear, readable fonts (12pt minimum)\n",
    "- **File Formats**: PDF/EPS for vector graphics, PNG for raster\n",
    "- **Panel Labels**: (A), (B), (C) for multi-panel figures\n",
    "- **Captions**: Comprehensive figure captions explaining all elements\n",
    "\n",
    "### Interactive Elements:\n",
    "\n",
    "For presentations and exploration:\n",
    "- Parameter sliders for sensitivity analysis\n",
    "- Zoom/pan capabilities for detailed examination\n",
    "- Animation for time-dependent solutions\n",
    "- Tooltip information for data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create completion summary\n",
    "print(\"ðŸŽ“ Visualization Gallery - Complete!\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "visualization_capabilities = [\n",
    "    \"âœ… 1D PDE solution plots with error analysis\",\n",
    "    \"âœ… 2D contour plots and 3D surface visualizations\",\n",
    "    \"âœ… MCMC trace diagnostics and convergence analysis\",\n",
    "    \"âœ… Joint posterior distributions with confidence ellipses\",\n",
    "    \"âœ… Uncertainty bands and prediction intervals\",\n",
    "    \"âœ… Certified vs Bayesian uncertainty comparison\",\n",
    "    \"âœ… Publication-quality figure generation\",\n",
    "    \"âœ… Academic styling and color schemes\"\n",
    "]\n",
    "\n",
    "print(\"ðŸŽ¯ Visualization Capabilities:\")\n",
    "for capability in visualization_capabilities:\n",
    "    print(f\"   {capability}\")\n",
    "\n",
    "print(\"\\nðŸš€ Next Steps:\")\n",
    "next_steps = [\n",
    "    \"ðŸ““ Notebook 06: Complete Workflow Demo\",\n",
    "    \"ðŸ““ Notebook 07: Advanced Examples\",\n",
    "    \"ðŸŽ¨ Customize plots for your specific problems\",\n",
    "    \"ðŸ“Š Create publication figures from your results\",\n",
    "    \"ðŸ–¼ï¸ Export figures in multiple formats\"\n",
    "]\n",
    "\n",
    "for step in next_steps:\n",
    "    print(f\"   {step}\")\n",
    "\n",
    "print(\"\\nðŸ’¡ Key Features Demonstrated:\")\n",
    "key_features = [\n",
    "    \"ðŸŽ¨ Professional academic styling\",\n",
    "    \"ðŸ“Š Comprehensive diagnostic plots\", \n",
    "    \"ðŸ” Multi-scale uncertainty visualization\",\n",
    "    \"ðŸ“ Publication-ready figure layouts\",\n",
    "    \"ðŸŒˆ Colorblind-friendly palettes\",\n",
    "    \"ðŸ“„ Multi-format export capabilities\"\n",
    "]\n",
    "\n",
    "for feature in key_features:\n",
    "    print(f\"   {feature}\")\n",
    "\n",
    "print(\"\\nðŸŽ‰ Visualization mastery achieved!\")\n",
    "print(\"ðŸ“ˆ Ready to create stunning scientific visualizations!\")\n",
    "\n",
    "# Generate summary statistics\n",
    "figures_created = 8\n",
    "visualization_types = 15\n",
    "style_options = 6\n",
    "\n",
    "print(f\"\\nðŸ“Š Gallery Statistics:\")\n",
    "print(f\"   Figures created: {figures_created}\")\n",
    "print(f\"   Visualization types: {visualization_types}\")\n",
    "print(f\"   Style options: {style_options}\")\n",
    "print(f\"   Export formats: 3 (PNG, PDF, EPS)\")\n",
    "print(\"   Quality level: Publication-ready! ðŸ†\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}